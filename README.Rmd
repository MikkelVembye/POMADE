---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

<img src="man/figures/POMADE_hex.png" align="right" alt="" width="180" />

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

```

# POMADE

<!-- badges: start -->
<!-- badges: end -->

The goal of the POMADE package is to provide approximation and plot functions for conducting power analysis  for tests based on the correlated-hierarchical effects (CHE), multi-level meta-analysis (MLMA), and correlated-effects (CE) models for meta-analysis of dependent effect sizes, with the possibility to vary assumptions about the variance estimation and the estimation of the degrees of freedom. These approximations also aim to replace Hedges & Pigott's (2001) previous power approximation based on the assumption of independence between effect sizes which has been shown to work inadequately to predict power for models that handle dependent effect sizes (Vembye, Pustejovsky, & Pigott, 2022).
## Installation

You can install the development version from [GitHub](https://github.com/) with:

```{r, eval = FALSE}

# install.packages("devtools")
devtools::install_github("MikkelVembye/POMADE")

```


## Example 

### Power for finding an effect size of practical concern

Example of how to approximate power for test based on the CHE-RVE model (Pustejovsky & Tipton, 2021).

```{r example, message=FALSE, warning=FALSE}

library(POMADE)
library(dplyr)

# Find more information regarding the used data by executing the following command below
# ?VWB22_pilot
coteach_dat <- VWB22_pilot
#glimpse(coteach_dat)

dat_kjsigma2j <- select(coteach_dat, kj, sigma2j = vg_ms_mean)


power_CHE_RVE_empirical <- 
  power_MADE(
    J = seq(40, 60, 5),
    mu = 0.1,
    tau = c(0.05, 0.1, 0.2),
    omega = c(0.1, 0.2),
    rho = c(0.2, 0.7),
    alpha = 0.05,
    sigma2_dist = dat_kjsigma2j$sigma2j,
    n_ES_dist = dat_kjsigma2j$kj,
    model = "CHE",  # Default
    var_df = "RVE", # Default
    iterations = 10, # default = 100 (recommended)
    seed = 10052510
  )
 
head(power_CHE_RVE_empirical, 10)

```

Making a power plot to assess power across a range of plausible scenarios

```{r example2, message=FALSE, warning=FALSE, fig.width=12, fig.height=7}

power_CHE_RVE_plot <- 
  plot_MADE(
    power_CHE_RVE_empirical,
    power_min = .8,
    expected_studies = c(45, 55)
  )

power_CHE_RVE_plot

```

### Minimum detectable effect size (MDES)

It is, moreover, possible to obtained the minimum detectable effect size (MDES) with a preset levels of significance and power. This can obtained from `mdes_MADE()`. 

```{r}

mdes_CHE_RVE_empirical <- 
  mdes_MADE(
    J = seq(60, 90, 10),
    tau = c(0, 0.25),
    omega = c(0, 0.1),
    rho = c(0.2, 0.7),
    target_power = .8,
    alpha = 0.05,
    sigma2_dist = dat_kjsigma2j$sigma2j,
    n_ES_dist = dat_kjsigma2j$kj,
    model = "CHE",  # Default
    var_df = "RVE", # Default
    iterations = 10, # Default = 100 (recommended)
    seed = 10052510
)

head(mdes_CHE_RVE_empirical, 10)


```

The MDES data can then be plotted across plausible scenarios via 

```{r example5, message=FALSE, warning=FALSE, fig.width=12, fig.height=7}

MDES_CHE_RVE_plot <- 
  plot_MADE(
    data = mdes_CHE_RVE_empirical, 
    es_min = 0.10,
    expected_studies = c(70, 80),
    numbers_ynudge = 0.159
  )

MDES_CHE_RVE_plot 
```

### Finding the number of studies needed to obtain a certain amount of power

The power approximation formulas can, furthermore, be used to understand how many studies are needed to find a given effect size considered to be of practical concern with a given amount of power. This can be conducted via `min_studies_MADE()`. 

```{r}

min_studies_example <- 
  min_studies_MADE(
    mu = c(0.1, 0.15, 0.2),
    tau = c(0.1, 0.2),
    omega = c(0, 0.1, 0.2, 0.3),
    rho = c(0.2, 0.7),
    target_power = .8,
    alpha = 0.05,
    sigma2_dist = dat_kjsigma2j$sigma2j,
    n_ES_dist = dat_kjsigma2j$kj,
    model = "CHE",  # Default
    var_df = "RVE", # Default
    iterations = 10, # Default = 100 (recommended)
    seed = 10052510,
)

head(min_studies_example, 10)


```

and plotted via

```{r, example3, message=FALSE, warning=FALSE, fig.width=8, fig.height=6}

min_studies_mu01 <- min_studies_example |> dplyr::filter(mu == 0.1)

min_studies_plot <- 
  plot_MADE(
    min_studies_mu01
  )

min_studies_plot 
  
```
Alternatively, reviewers can investigate how the number of studies needed varies across various values of the effect size of practical concern.

```{r, example4, message=FALSE, warning=FALSE, fig.width=12, fig.height=7}

min_studies_plot2 <- 
  plot_MADE(
    min_studies_example
  )

min_studies_plot2

```
  

### Traffic light power plot

Traffic light plots aim to flesh out the likelihood of the given assumptions made by the reviewers/meta-analyst, and can be specified in `plot_MADE()`, as below. Assumptions should be specified from the upper left to the lower right facet grid plot.

```{r example7, message=FALSE, warning=FALSE, fig.width=12, fig.height=7}

# To save plot use below commands
#png("traffic_light_power_plot.png", height = 7,  width = 12, units = "in", res = 600)
plot_MADE(
  power_CHE_RVE_empirical,
  power_min = .8,
  expected_studies = c(45, 55),
  traffic_light_assumptions = c("unlikely", "likely", "expected", "expected", "likely")
)
#dev.off()
```


# Acknowledgments 
Thanks to [Savhannah Schulz](https://savhannahschulz.netlify.app/) for making our hex stickers.   

# Reference

Hedges, L. V., & Pigott T. D. (2001). The power of statistical tests in meta-analysis. *Psychological Methods*, 6(3), 203-217. <https://doi.org/10.1037/1082-989X.6.3.203>

Pustejovsky, J. E., & Tipton E. (2021).Meta-analysis with robust variance estimation: Expanding the range of working models. *Prevention Science*, 23(1), 425-438. <https://doi.org/10.1007/s11121-021-01246-3>

Vembye, M. H., Pustejovsky, J. E., & Pigott, T. D. (2022). Power approximations for overall average effects in meta-analysis with dependent effect sizes. *Journal of Educational and Behavioral Statistics*, 1â€“33. <https://doi.org/10769986221127379>
